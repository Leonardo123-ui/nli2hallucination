# å¿«é€Ÿè¡ŒåŠ¨æŒ‡å— - Model 5: å…³ç³»ç±»å‹ä¼˜åŒ–

**æ‰§è¡Œæ—¶é—´**: 10 åˆ†é’Ÿä¿®æ”¹ + 1.5 å°æ—¶è®­ç»ƒ
**é¢„æœŸæ”¹è¿›**: 0.5611 â†’ 0.57-0.58

---

## æ ¸å¿ƒæƒ³æ³•

å½“å‰æ¨¡å‹ä½¿ç”¨ **20 ä¸ªå…³ç³»ç±»å‹**ï¼Œå¯¼è‡´ï¼š
- âŒ æ¨¡å‹å‚æ•°è¿‡å¤š (æ¯ä¸ªå…³ç³»éƒ½è¦å•ç‹¬çš„ GAT)
- âŒ æŸäº›å…³ç³»ï¼ˆå¦‚ "span"ï¼‰å¯¹åˆ†ç±»æ— ç”¨
- âŒ æ•°æ®ç¨€ç–ï¼ˆ900 ä¸ªæ ·æœ¬åˆ†æ•£åœ¨ 20 ä¸ªå…³ç³»ä¸Šï¼‰

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å·²ç»å®šä¹‰å¥½çš„ **9 ä¸ªå…³é”®å…³ç³»** (`rel_names_short`)
- âœ… å‡å°‘å‚æ•°çº¦ 55%
- âœ… ä¸“æ³¨äºé‡è¦çš„è¯­ç¯‡å…³ç³»
- âœ… é™ä½è¿‡æ‹Ÿåˆé£é™©

---

## ä¸¤ä¸ªä¿®æ”¹ç‚¹

### ä¿®æ”¹ 1: train.py ç¬¬ 496 è¡Œ

**å½“å‰ä»£ç **:
```python
model.merge_graphs(g_p1, g_p2, lc, rel_names_long)
```

**æ”¹ä¸º**:
```python
model.merge_graphs(g_p1, g_p2, lc, rel_names_short)
```

### ä¿®æ”¹ 2: train.py ç¬¬ 718 è¡Œ

**å½“å‰ä»£ç **:
```python
model = ExplainableHeteroClassifier(
    in_dim=in_dim,
    hidden_dim=hidden_dim,
    n_classes=n_classes,
    rel_names=rel_names_long,  # â† è¿™é‡Œ
)
```

**æ”¹ä¸º**:
```python
model = ExplainableHeteroClassifier(
    in_dim=in_dim,
    hidden_dim=hidden_dim,
    n_classes=n_classes,
    rel_names=rel_names_short,  # â† æ”¹æˆ short
)
```

---

## æ‰§è¡Œæ­¥éª¤

### Step 1: å¤‡ä»½åŸæ–‡ä»¶
```bash
cd /mnt/nlp/yuanmengying/nli2hallucination/data/cdcl-nli
cp train.py train.py.backup_before_model5
```

### Step 2: æ‰“å¼€ç¼–è¾‘å™¨ä¿®æ”¹
```bash
nano train.py
```

**æ‰¾åˆ°ç¬¬ 496 è¡Œ**:
- æŒ‰ `Ctrl+G` è·³è½¬åˆ°è¡Œå·
- è¾“å…¥ 496
- æ‰¾åˆ° `rel_names_long` æ”¹ä¸º `rel_names_short`

**æ‰¾åˆ°ç¬¬ 718 è¡Œ**:
- æŒ‰ `Ctrl+G` è·³è½¬åˆ°è¡Œå·
- è¾“å…¥ 718
- æ‰¾åˆ° `rel_names_long` æ”¹ä¸º `rel_names_short`

**ä¿å­˜**:
- `Ctrl+O`, `Enter`, `Ctrl+X`

### Step 3: éªŒè¯ä¿®æ”¹
```bash
# ç¡®è®¤ä¸¤å¤„éƒ½æ”¹äº†
grep -n "rel_names" train.py | grep -E "496|718"

# è¾“å‡ºåº”è¯¥åŒ…å«ï¼š
# 496: ...rel_names_short...
# 718: ...rel_names=rel_names_short...
```

### Step 4: å¯åŠ¨è®­ç»ƒ
```bash
CUDA_VISIBLE_DEVICES=0 python train.py > training_model5.log 2>&1 &
echo "Training started, log: training_model5.log"
```

### Step 5: ç›‘æ§è¿›åº¦
```bash
# å®æ—¶æŸ¥çœ‹
tail -f training_model5.log

# æˆ–æ¯ 30 ç§’æ£€æŸ¥ä¸€æ¬¡
watch -n 30 'grep "f1_macro_cli" training_model5.log | tail -3'
```

### Step 6: å¯¹æ¯”ç»“æœ (è®­ç»ƒå®Œæˆå)
```bash
echo "=== ç»“æœå¯¹æ¯” ==="
echo "Model 3 (baseline with alpha=[1.0, 3.4]):"
grep -o 'f1_macro_cli: 0\.[0-9]*' training_model3.log | tail -1

echo "Model 5 (rel_names_short):"
grep -o 'f1_macro_cli: 0\.[0-9]*' training_model5.log | tail -1

echo ""
echo "æ”¹è¿›:"
python3 << 'PYEOF'
import re
with open('training_model3.log') as f:
    m3 = float(re.findall(r'f1_macro_cli: (0\.\d+)', f.read())[-1])
with open('training_model5.log') as f:
    m5 = float(re.findall(r'f1_macro_cli: (0\.\d+)', f.read())[-1])
print(f"Model 5 vs Model 3: {m5 - m3:+.4f}")
PYEOF
```

---

## é¢„æœŸç»“æœ

| æŒ‡æ ‡ | Model 3 | Model 5 | å˜åŒ– |
|------|---------|---------|------|
| Macro F1 | 0.5611 | **0.57-0.58** | âœ… +0.01-0.02 |
| Precision | 0.5597 | ? | ? |
| Recall | 0.5631 | ? | ? |
| æ¨¡å‹å‚æ•° | 20 rel | **9 rel** | -55% |

---

## å¦‚æœæ”¹è¿›æˆåŠŸ (>0.005)

ç«‹å³è¿›è¡Œ **Model 6: ç½‘ç»œæ·±åº¦å¢åŠ **

```
ä¿®æ”¹ build_base_graph_extract.py ä¸­ RGAT ç±»çš„ conv2:

å½“å‰:
    num_heads=1,  # â† åªæœ‰ 1 ä¸ªå¤´

æ”¹ä¸º:
    num_heads=4,  # â† å¢åŠ åˆ° 4 ä¸ªå¤´

è¿™æ ·ç¬¬äºŒå±‚å°±èƒ½åˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›çš„ä¼˜åŠ¿
```

---

## å¦‚æœæ•ˆæœä¸å¦‚é¢„æœŸ (<0.005)

å›é€€åˆ° Model 3ï¼Œå°è¯•å…¶ä»–æ–¹å‘ï¼š

```bash
# æ¢å¤åŸæ–‡ä»¶
cp train.py.backup_before_model5 train.py

# å°è¯•æ··åˆæ–¹æ¡ˆï¼šå…³é”®å…³ç³» + æ›´å¤šå…³ç³»
# å®šä¹‰ä¸€ä¸ª 15 ä¸ªå…³ç³»çš„ä¸­é—´åˆ—è¡¨
rel_names_medium = [
    "Temporal", "TextualOrganization", "Joint", "Topic-Comment",
    "Comparison", "Condition", "Contrast", "Evaluation", "Topic-Change",
    "Summary", "Attribution", "Cause", "Background", "Elaboration",
    "Explanation", "lexical"
]

# ç”¨è¿™ä¸ªæ›¿ä»£ rel_names_short æˆ– rel_names_long
```

---

## å…³é”®ä»£ç ä½ç½®å¿«é€ŸæŸ¥æ‰¾

```bash
# æ‰¾åˆ°ç¬¬ä¸€å¤„ä¿®æ”¹ç‚¹
grep -n "merge_graphs.*rel_names" train.py

# æ‰¾åˆ°ç¬¬äºŒå¤„ä¿®æ”¹ç‚¹
grep -n "rel_names=rel_names" train.py

# æŸ¥çœ‹ä¸¤ä¸ªåˆ—è¡¨çš„å®šä¹‰
grep -n "rel_names_long\|rel_names_short" train.py | head -40
```

---

## å¸¸è§é—®é¢˜

**Q: åªæ”¹è¿™ä¸¤è¡ŒçœŸçš„æœ‰æ•ˆæœå—ï¼Ÿ**
A: æ˜¯çš„ï¼Œå› ä¸ºè¿™å½±å“åˆ°ï¼š
   1. å›¾çš„æ„å»ºæ–¹å¼ (merge_graphs)
   2. æ¨¡å‹çš„åˆå§‹åŒ– (ExplainableHeteroClassifier)
   ä¸¤å¤„éƒ½æ”¹æ‰èƒ½ç¡®ä¿ä¸€è‡´æ€§

**Q: æ”¹äº†ä¹‹åè¦é‡æ–°è®­ç»ƒå—ï¼Ÿ**
A: æ˜¯çš„ï¼Œéœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒã€‚æ¨¡å‹ç»“æ„æ”¹å˜äº†ã€‚

**Q: å¦‚æœ Macro F1 ä¸‹é™æ€ä¹ˆåŠï¼Ÿ**
A: è¿™è¯´æ˜çŸ­åˆ—è¡¨å¯èƒ½ä¸¢å¤±äº†é‡è¦å…³ç³»ã€‚å¯ä»¥ï¼š
   - å°è¯•æ·»åŠ å›æŸäº›å…³ç³»ï¼ˆå¦‚ "Attribution", "Enablement"ï¼‰
   - å®šä¹‰ä¸€ä¸ª 15-18 ä¸ªå…³ç³»çš„ä¸­é—´åˆ—è¡¨
   - å›åˆ° Model 3 + ç½‘ç»œæ”¹è¿›çš„æ–¹å‘

---

## ä¸‹ä¸€æ­¥ï¼ˆå¦‚æœæˆåŠŸï¼‰

```
Model 5 æˆåŠŸ (æ”¹è¿› > 0.005)
  â†“
Model 6: æ”¹è¿›æ³¨æ„åŠ›å¤´æ•° (5 åˆ†é’Ÿä¿®æ”¹ + 1.5h è®­ç»ƒ)
  â†“
Model 7: æ·»åŠ ç½‘ç»œæ·±åº¦ (30 åˆ†é’Ÿä¿®æ”¹ + 2h è®­ç»ƒ)
  â†“
æœ€ç»ˆç›®æ ‡: 0.59-0.60+
```

---

**ç°åœ¨å°±å¼€å§‹ä¿®æ”¹å§ï¼é¢„è®¡ 1.5 å°æ—¶åè§åˆ°ç»“æœã€‚** ğŸš€

