{
  "model_name": "/mnt/second/yuanmengying/llm-models/llama3.1-8b-instruct",
  "deploy_type": "huggingface",
  "inference_time": "2025-12-22T00:36:56.355729",
  "test_size": 900,
  "valid_predictions": 900,
  "use_zh_prompt": false,
  "detailed_metrics": {
    "accuracy": 0.23666666666666666,
    "macro_precision": 0.48136089372124974,
    "macro_recall": 0.49780256930358346,
    "macro_f1": 0.2029905578292675,
    "no_hallucination": {
      "precision": 0.7368421052631579,
      "recall": 0.020114942528735632,
      "f1_score": 0.039160839160839164,
      "support": 696
    },
    "hallucination": {
      "precision": 0.22587968217934165,
      "recall": 0.9754901960784313,
      "f1_score": 0.36682027649769583,
      "support": 204
    },
    "confusion_matrix": {
      "true_negatives": 14,
      "false_positives": 682,
      "false_negatives": 5,
      "true_positives": 199
    },
    "specificity": 0.020114942528735632,
    "sensitivity": 0.9754901960784313,
    "false_positive_rate": 0.9798850574712644,
    "false_negative_rate": 0.024509803921568627
  },
  "classification_report": {
    "No Hallucination": {
      "precision": 0.7368421052631579,
      "recall": 0.020114942528735632,
      "f1-score": 0.039160839160839164,
      "support": 696.0
    },
    "Hallucination": {
      "precision": 0.22587968217934165,
      "recall": 0.9754901960784313,
      "f1-score": 0.36682027649769583,
      "support": 204.0
    },
    "accuracy": 0.23666666666666666,
    "macro avg": {
      "precision": 0.48136089372124974,
      "recall": 0.49780256930358346,
      "f1-score": 0.2029905578292675,
      "support": 900.0
    },
    "weighted avg": {
      "precision": 0.6210239560308263,
      "recall": 0.23666666666666666,
      "f1-score": 0.11343031162386001,
      "support": 900.0
    }
  }
}